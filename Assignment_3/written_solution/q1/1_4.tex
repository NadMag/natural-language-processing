\subsubsection*{(a)}
We define $q_1=q_2=(\mu_a + \mu_b)H$. Due to the analysis in previous clauses we know that both $c_1,c_2$ are equal to $\frac{1}{2}(v_a+v_b)$ under this definition of $q_1,q_2$. \newline
Hence, their average is also equal to $\frac{1}{2}(v_a+v_b)$.
\subsubsection*{(b)}
Let us denote the value $c$ that we've gotten in clause 1.3b by $c^*$. We've seen that $E[c^*]=\frac{1}{2}(v_a+v_b)$ with some variance we denote by $\sigma^*$. 
Let us note that $c_1,c_2$ are equal to $c^*$ (under the same sampling, of course, as they are random variables). Hence, we get that $E[c_1]=E[c_2]=\frac{1}{2}(v_a+v_b)$ and that $Var[c_1]=Var[c_2]=\sigma^*$. \newline
Our $c$ is equal to $\frac{1}{2}(c_1+c_2)$. Hence, we get that $E[c]=\frac{1}{2}(E[c_1]+E[c_2])=\frac{1}{2}(v_a+v_b)$ and that $Var[c]=\frac{1}{4}(Var[c_1]+Var[c_2])=\frac{1}{2}\sigma^*$. \newline
We've been able to keep the same expectation and reduce the variance by a factor of $2$, using multi-head attention. 